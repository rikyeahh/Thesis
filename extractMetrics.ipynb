{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from collections import Counter\n",
    "from skimage.morphology import thin\n",
    "from PIL import Image\n",
    "import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_branchpoints(skeleton):\n",
    "    #skeleton = skeleton.astype(int)\n",
    "    return find_endpoints(skeleton) - 2\n",
    "\n",
    "def find_endpoints(img):\n",
    "    # Find row and column locations that are non-zero\n",
    "    (rows,cols) = np.nonzero(img)\n",
    "\n",
    "    # Initialize empty list of co-ordinates\n",
    "    skel_coords = []\n",
    "\n",
    "    # For each non-zero pixel...\n",
    "    for (r,c) in zip(rows,cols):\n",
    "\n",
    "        # Extract an 8-connected neighbourhood\n",
    "        (col_neigh,row_neigh) = np.meshgrid(np.array([c-1,c,c+1]), np.array([r-1,r,r+1]))\n",
    "\n",
    "        # Cast to int to index into image\n",
    "        col_neigh = col_neigh.astype('int')\n",
    "        row_neigh = row_neigh.astype('int')\n",
    "\n",
    "        # Convert into a single 1D array and check for non-zero locations\n",
    "        pix_neighbourhood = img[row_neigh,col_neigh].ravel() != 0\n",
    "\n",
    "        # If the number of non-zero locations equals 2, add this to \n",
    "        # our list of co-ordinates\n",
    "        if np.sum(pix_neighbourhood) == 2:\n",
    "            skel_coords.append((r,c))\n",
    "\n",
    "    return len(skel_coords)\n",
    "\n",
    "def detect_fused(img):\n",
    "\n",
    "    n_fused = 0\n",
    "    n_single = 0\n",
    "\n",
    "    img_thinned = thin(img) # or skeletonize, small difference\n",
    "    img_thinned[0,:] = 0\n",
    "    img_thin_labeled = skimage.measure.label(img_thinned.astype(np.uint8), connectivity=2)\n",
    "    img_labeled = skimage.measure.label(img.astype(np.uint8), connectivity=2)\n",
    "    stats_bbox = skimage.measure.regionprops(img_thin_labeled.astype(np.uint8))\n",
    "    # results to fill\n",
    "    fused_image = np.zeros_like(img)\n",
    "    singles_image = np.zeros_like(img)\n",
    "    finish = np.zeros_like(img)\n",
    "\n",
    "    for i in range(0, len(stats_bbox)):\n",
    "\n",
    "        bbox = stats_bbox[i].bbox\n",
    "        # take thinned branch region\n",
    "        bbox_region = img_thin_labeled[bbox[0]:bbox[2], bbox[1]:bbox[3]]\n",
    "\n",
    "        # take its largest connected component in case multiple accidentally are in that bounding box\n",
    "        value_counts = Counter(bbox_region.flatten()).most_common()\n",
    "        most_frequent_value = value_counts[1][0] if len(value_counts) > 1 else value_counts[0][0]\n",
    "        bbox_region = (bbox_region == most_frequent_value) * 1\n",
    "\n",
    "        # if into that bounding box #branchpoints > 1 AND #endpoints >= 4, it is a FUSED filopodia\n",
    "        bbox_region_padded = np.pad(bbox_region, pad_width=4, mode='constant', constant_values=0)\n",
    "        n_endpoints = find_endpoints(bbox_region_padded)\n",
    "        n_branchpoints = find_branchpoints(bbox_region_padded)\n",
    "        is_fused = n_branchpoints > 1 and n_endpoints >= 4\n",
    "\n",
    "        # mark FUSED and SINGLE regions with 2 different values\n",
    "        if is_fused:\n",
    "            fused_image += (img_labeled == (i + 1))\n",
    "            n_fused += 1\n",
    "        else:\n",
    "            singles_image += (img_labeled == (i + 1))\n",
    "            n_single += 1\n",
    "\n",
    "        finish = singles_image + fused_image * 2\n",
    "\n",
    "    return finish, n_single, n_fused\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(prediction, true_mask):\n",
    "    intersection = np.logical_and(prediction, true_mask).sum()\n",
    "    union = np.logical_or(prediction, true_mask).sum()\n",
    "    iou_score = intersection / union\n",
    "    return iou_score\n",
    "\n",
    "def dice(prediction, true_mask):\n",
    "    intersection = np.logical_and(prediction, true_mask).sum()\n",
    "    dice_score = (2. * intersection) / (prediction.sum() + true_mask.sum())\n",
    "    return dice_score\n",
    "\n",
    "def precision(prediction, true_mask):\n",
    "    true_positives = np.logical_and(prediction, true_mask).sum()\n",
    "    false_positives = np.logical_and(prediction, np.logical_not(true_mask)).sum()\n",
    "    precision_score = true_positives / (true_positives + false_positives)\n",
    "    return precision_score\n",
    "\n",
    "\n",
    "def recall(prediction, true_mask):\n",
    "    true_positives = np.logical_and(prediction, true_mask).sum()\n",
    "    false_negatives = np.logical_and(np.logical_not(prediction), true_mask).sum()\n",
    "    if int(true_positives + false_negatives) == 0:\n",
    "        return 0\n",
    "    recall_score = true_positives / (true_positives + false_negatives)\n",
    "    return recall_score\n",
    "\n",
    "def f1_score(prediction, true_mask):\n",
    "    p = precision(prediction, true_mask)\n",
    "    r = recall(prediction, true_mask)\n",
    "    if precision == 0:\n",
    "        return 0\n",
    "    f1 = 2 * (p * r) / (p + r)\n",
    "    return f1\n",
    "\n",
    "import skimage\n",
    "from skimage.morphology import thin\n",
    "from collections import Counter\n",
    "\n",
    "def mse(prediction, true_mask):\n",
    "    mse_score = np.mean((prediction - true_mask) ** 2)\n",
    "    return mse_score\n",
    "\n",
    "def num_filopodia_blobs(mask):\n",
    "    return skimage.measure.label(mask)\n",
    "\n",
    "def num_filopodia_demerged(mask):\n",
    "    thinned = thin(mask)\n",
    "    img_thin_labeled = skimage.measure.label(thinned.astype(np.uint8), connectivity=2)\n",
    "    stats_bbox = skimage.measure.regionprops(img_thin_labeled.astype(np.uint8))\n",
    "    filopodia_count = 0\n",
    "    for i in range(0, len(stats_bbox)):\n",
    "        bbox = stats_bbox[i].bbox\n",
    "        bbox_region = img_thin_labeled[bbox[0]:bbox[2], bbox[1]:bbox[3]]\n",
    "\n",
    "        value_counts = Counter(bbox_region.flatten()).most_common()\n",
    "        most_frequent_value = value_counts[1][0] if len(value_counts) > 1 else value_counts[0][0]\n",
    "        bbox_region = (bbox_region == most_frequent_value) * 1\n",
    "\n",
    "        # if into that bounding box #branchpoints > 1 AND #endpoints >= 4, it is a FUSED filopodia\n",
    "        bbox_region_padded = np.pad(bbox_region, pad_width=4, mode='constant', constant_values=0)\n",
    "        n_endpoints = find_endpoints(bbox_region_padded)\n",
    "        \n",
    "        filopodia_count += n_endpoints - 1\n",
    "    return filopodia_count\n",
    "\n",
    "def filopodia_length_sum(mask):\n",
    "    return np.count_nonzero(thin(mask))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IOUs, DICEs, PRECISIONs, RECALLs, F1SCOREs, MSEs = [],[],[],[],[],[]\n",
    "filo_N_diffs, filo_N_abs_diffs, filo_len_diffs, filo_len_abs_diffs = [],[],[],[]\n",
    "single_filo_N_diff, single_filo_N_abs_diff, merged_filo_N_diff, merged_filo_N_abs_diff = [],[],[],[]\n",
    "test_set_indices = list(pd.read_excel(\"dataset/test_set_indices.xlsx\")[\"id\"])\n",
    "img_directory = r\"dataset\\images\"\n",
    "mask_directory = r\"dataset\\masks\"\n",
    "pred_directory = r\"toolsData\\FiloAnalyzer320\"\n",
    "plt.rcParams[\"figure.figsize\"] = (15,15)\n",
    "\n",
    "IMG_HEIGHT, IMG_WIDTH = 320, 320\n",
    "\n",
    "\n",
    "for i in tqdm.tqdm(range(1,244+1)):\n",
    "    if not (i in test_set_indices):\n",
    "        continue\n",
    "    filename = f\"{i}.tif\"\n",
    "    img = cv2.imread(os.path.join(img_directory, filename))\n",
    "    mask = cv2.imread(os.path.join(mask_directory, filename))\n",
    "    pred = cv2.imread(os.path.join(pred_directory, f\"{i}.tif\"))#.mean(axis=-1)\n",
    "\n",
    "    # for Filopodyan\n",
    "    # pred = (pred[:,:,0] >= pred.mean()) * 255\n",
    "\n",
    "\n",
    "    # for FiloQuant\n",
    "    # filename = os.listdir(r\"C:\\Users\\ricca\\Desktop\\Thesis\\toolsData\\FiloQuant320\" + \"\\\\\" + str(i) + \"\\\\Tagged_skeleton_RGB\")[0]\n",
    "    # path = os.path.join(r\"C:\\Users\\ricca\\Desktop\\Thesis\\toolsData\\FiloQuant320\" + \"\\\\\" + str(i) + \"\\\\Tagged_skeleton_RGB\", filename)\n",
    "    # pred = np.array(Image.open(path))\n",
    "    # pred = ((pred[:,:,0] > 100) & (pred[:,:,1] < 100)).astype(np.uint8) * 255\n",
    "\n",
    "    # for FiloDetect\n",
    "    #pred = (pred[:,:,1] > pred.mean()) & (pred[:,:,2] < pred.mean())\n",
    "\n",
    "    #print(\"preprocessing\", end=\" \")\n",
    "\n",
    "    # preprocess the image\n",
    "    if len(img.shape) > 2:\n",
    "        img = img.mean(axis=-1)\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    img = img.reshape((1, IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "\n",
    "    # preprocess the mask\n",
    "    if len(mask.shape) > 2:\n",
    "        mask = mask.mean(axis=-1)\n",
    "    mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    mask = (mask > 0.80) * 255\n",
    "\n",
    "    # preprocess the pred\n",
    "    if len(pred.shape) > 2:\n",
    "        pred = pred.mean(axis=-1)\n",
    "    pred = resize(pred, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    pred = (pred > 0.80) * 255\n",
    "\n",
    "    # for the deep learning model\n",
    "    pred = model.predict(img, verbose=0).reshape((IMG_HEIGHT, IMG_WIDTH))\n",
    "    pred = cv2.erode(pred, np.ones((2, 2), np.uint8))\n",
    "    pred = (pred > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "    # filter smallest contours\n",
    "    # contours, _ = cv2.findContours(pred.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # filtered_contours = []\n",
    "    # for contour in contours:\n",
    "    #     area = cv2.contourArea(contour)\n",
    "    #     if area > 25:\n",
    "    #         filtered_contours.append(contour)\n",
    "    # filtered_image = np.zeros_like(pred)\n",
    "    # cv2.drawContours(filtered_image, filtered_contours, -1, 255, thickness=cv2.FILLED)\n",
    "    # pred = filtered_image\n",
    "    \n",
    "    #print(\"detecting fused\", end=\" \")\n",
    "    fused_pred, n_single_p, n_fused_p = detect_fused(pred)\n",
    "    fused_true, n_single_t, n_fused_t = detect_fused(mask)\n",
    "    #print(\"finish\")\n",
    "\n",
    "\n",
    "    # plt.imshow(pred), plt.show()\n",
    "    # plt.imshow(mask), plt.show()\n",
    "\n",
    "    IOUs.append(iou(pred, mask))\n",
    "    DICEs.append(dice(pred, mask))\n",
    "    PRECISIONs.append(precision(pred, mask))\n",
    "    RECALLs.append(recall(pred, mask))\n",
    "    F1SCOREs.append(f1_score(pred, mask))\n",
    "    MSEs.append(mse(pred, mask))\n",
    "    filo_N_diffs.append(num_filopodia_demerged(pred) - num_filopodia_demerged(mask))\n",
    "    filo_N_abs_diffs.append(abs(num_filopodia_demerged(pred) - num_filopodia_demerged(mask)))\n",
    "    filo_len_diffs.append(filopodia_length_sum(pred) - filopodia_length_sum(mask))\n",
    "    filo_len_abs_diffs.append(abs(filopodia_length_sum(pred) - filopodia_length_sum(mask)))\n",
    "    single_filo_N_diff.append(n_single_p - n_single_t)\n",
    "    single_filo_N_abs_diff.append(abs(n_single_p - n_single_t))\n",
    "    merged_filo_N_diff.append(n_fused_p - n_fused_t)\n",
    "    merged_filo_N_abs_diff.append(abs(n_fused_p - n_fused_t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IOU\", np.mean(IOUs), \"±\", np.std(IOUs))\n",
    "print(\"DICE\", np.mean(DICEs), \"±\", np.std(DICEs))\n",
    "print(\"PRECISION\", np.nanmean(PRECISIONs), \"±\", np.nanstd(PRECISIONs))\n",
    "print(\"RECALL\", np.mean(RECALLs), \"±\", np.std(RECALLs))\n",
    "print(\"F1\", np.nanmean(F1SCOREs), \"±\", np.nanstd(F1SCOREs))\n",
    "print(\"MSE\", np.mean(MSEs), \"±\", np.std(MSEs))\n",
    "print(\"Filo # difference\", np.mean(filo_N_diffs), \"±\", np.std(filo_N_diffs))\n",
    "print(\"Filo # abs difference\", np.mean(filo_N_abs_diffs), \"±\", np.std(filo_N_abs_diffs))\n",
    "print(\"Filo len difference\", np.mean(filo_len_diffs), \"±\", np.std(filo_len_diffs))\n",
    "print(\"Filo len abs difference\", np.mean(filo_len_abs_diffs), \"±\", np.std(filo_len_abs_diffs))\n",
    "print(\"Single filo # diff\", np.mean(single_filo_N_diff), \"±\", np.std(single_filo_N_diff))\n",
    "print(\"Single filo # abs diff\", np.mean(single_filo_N_abs_diff), \"±\", np.std(single_filo_N_abs_diff))\n",
    "print(\"Fused filo # diff\", np.mean(merged_filo_N_diff), \"±\", np.std(merged_filo_N_diff))\n",
    "print(\"Fused filo # abs diff\", np.mean(merged_filo_N_abs_diff), \"±\", np.std(merged_filo_N_abs_diff))\n",
    "print(np.mean(IOUs), \"±\", np.std(IOUs), \",\",\n",
    "        np.mean(DICEs), \"±\", np.std(DICEs), \",\",\n",
    "        np.nanmean(PRECISIONs), \"±\", np.nanstd(PRECISIONs), \",\",\n",
    "        np.mean(RECALLs), \"±\", np.std(RECALLs), \",\",\n",
    "        np.nanmean(F1SCOREs), \"±\", np.nanstd(F1SCOREs), \",\",\n",
    "        np.mean(MSEs), \"±\", np.std(MSEs), \",\",\n",
    "        np.mean(filo_N_diffs), \"±\", np.std(filo_N_diffs), \",\",\n",
    "        np.mean(filo_N_abs_diffs), \"±\", np.std(filo_N_abs_diffs), \",\",\n",
    "        np.mean(filo_len_diffs), \"±\", np.std(filo_len_diffs), \",\",\n",
    "        np.mean(filo_len_abs_diffs), \"±\", np.std(filo_len_abs_diffs), \",\",\n",
    "        np.mean(single_filo_N_diff), \"±\", np.std(single_filo_N_diff) , \",\",\n",
    "        np.mean(single_filo_N_abs_diff), \"±\", np.std(single_filo_N_abs_diff) , \",\",\n",
    "        np.mean(merged_filo_N_diff), \"±\", np.std(merged_filo_N_diff) , \",\",\n",
    "        np.mean(merged_filo_N_abs_diff), \"±\", np.std(merged_filo_N_abs_diff) , \",\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
